{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Beale function\n",
    "def beale_function(x,y):\n",
    "    \"\"\"\n",
    "    Equation of beale function\n",
    "\n",
    "    Inputs:\n",
    "    x and y values\n",
    "\n",
    "    Outputs:\n",
    "    Value of beale function at x and y\n",
    "    \"\"\"\n",
    "    return (1.5-x+x*y)**2 + (2.25-x+x*y**2)**2 + (2.625-x+x*y**3)**2\n",
    "# Generating data for beale function in range in the range -4.5 < x,y < 4.5 with step size 0.2\n",
    "import numpy as np\n",
    "X,Y,Z = [],[],[] # Empty lists to store x,y and output values\n",
    "for i in np.arange(-4.5,4.6,0.2): # -4.5 < x < 4.5\n",
    "    for j in np.arange(-4.5,4.6,0.2): # -4.5 < y < 4.5\n",
    "        X.append(i) # Adding x value to list X\n",
    "        Y.append(j) # Adding y value to list Y\n",
    "        Z.append(beale_function(i,j)) # Adding beale function value for respective x and y to list Z\n",
    "data1 = zip(X,Y,Z) # Concatenation of inputs and outputs\n",
    "import pandas as pd\n",
    "data2 = pd.DataFrame(data1,columns=['x','y','z']) # Creating a dataframe containing inputs and outputs\n",
    "# data2 now has 3 columns containing x, y, f(x,y) values for beale function in the range of -4.5 < x,y < 4.5 with step size 0.2\n",
    "data2.head()\n",
    "# Saving data to a excel file\n",
    "data2.to_excel('beale_function_data_step=0.2.xlsx',index=False)\n",
    "# Reading data from excel sheet\n",
    "data3 = pd.read_excel('beale_function_data_step=0.2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data - preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_dataset = scaler.fit_transform(data3.values) # Normalizing data between 0 and 1 using MinMaxScaler\n",
    "# Splitting the data into inputs and outputs\n",
    "inputs = scaled_dataset[:,0:2] # Splitting inputs from normalized data\n",
    "output = scaled_dataset[:,-1] # Splitting output from normalized data\n",
    "# Splitting the data into training data and testing data using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "inputs_train,inputs_test,output_train,output_test = train_test_split(inputs,output,train_size=0.7,random_state=0) # train_size=0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential() # Creating ANN model\n",
    "model.add(Dense(64,input_dim=2,activation='relu')) # First layer with 18 nodes and two inputs and \"relu\" as activation function\n",
    "model.add(Dense(16,activation='relu')) # Second layer with 12 nodes and \"relu\" as activation function\n",
    "model.add(Dense(1,activation='linear')) # Output layer with one output and \"linear\" as activation function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam',loss='MSE') # Compiling using optimizer \"adam\" and loss function \"MSE\"\n",
    "history = model.fit(inputs_train,output_train,epochs=100,validation_split=0.15) # Training data with 100 epochs and validation split 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(inputs_train) # Prediction of training data\n",
    "pred_test = model.predict(inputs_test) # Prediction of testing data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_train = r2_score(output_train,pred_train) # R2 score of training data\n",
    "print(f\"R2 Score for training data: {r2_train:.4f}\")\n",
    "r2_test = r2_score(output_test,pred_test) # R2 score of testing data\n",
    "print(f\"R2 Score for testing data: {r2_test:.4f}\")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train = mean_squared_error(output_train,pred_train) # MSE of training data\n",
    "print(f\"Mean Squared Error for training data: {mse_train:.4f}\")\n",
    "mse_test = mean_squared_error(output_test,pred_test) # MSE of Testing data\n",
    "print(f\"Mean Squared Error for testing data: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots - Training Data Vs Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,plot = plt.subplots(1,2,figsize=(10,5))\n",
    "plot[0].plot(output_train,pred_train,'y.')\n",
    "plot[0].plot(output_train,output_train,'-')\n",
    "plot[0].set_xlabel('True output')\n",
    "plot[0].set_ylabel('Predicted output')\n",
    "plot[0].set_ylim(-0.05,1.1)\n",
    "plot[0].set_xlim(-0.05,1.1)\n",
    "plot[0].set_title(f'Training Data (adam)')\n",
    "plot[0].text(0,1,f'R2 = {r2_train:.4f}',fontsize=12,color='magenta')\n",
    "plot[1].plot(output_test,pred_test,'r*')\n",
    "plot[1].plot(output_test,output_test,'-')\n",
    "plot[1].set_ylim(-0.05,1)\n",
    "plot[1].set_xlim(-0.05,1)\n",
    "plot[1].set_xlabel('True output')\n",
    "plot[1].set_ylabel('Predicted output')\n",
    "plot[1].set_title(f'Testing Data (adam)')\n",
    "plot[1].text(0,0.9,f'R2 = {r2_test:.4f}',fontsize=12,color='magenta')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using \"RMSProp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='RMSProp',loss='MSE') # Compiling using optimizer \"RMSProp\" and loss function \"MSE\"\n",
    "history = model.fit(inputs_train,output_train,epochs=100,validation_split=0.15) # Training data with 100 epochs and validation split 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train2 = model.predict(inputs_train) # Prediction of training data\n",
    "pred_test2 = model.predict(inputs_test) # Prediction of testing data\n",
    "from sklearn.metrics import r2_score\n",
    "r2_train2 = r2_score(output_train,pred_train2) # R2 score of training data\n",
    "print(f\"R2 Score for training data: {r2_train2:.4f}\")\n",
    "r2_test2 = r2_score(output_test,pred_test2) # R2 score of testing data\n",
    "print(f\"R2 Score for testing data: {r2_test2:.4f}\")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_train2 = mean_squared_error(output_train,pred_train2) # MSE of training data\n",
    "print(f\"Mean Squared Error for training data: {mse_train:.4f}\")\n",
    "mse_test2 = mean_squared_error(output_test,pred_test2) # MSE of testing data\n",
    "print(f\"Mean Squared Error for testing data: {mse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Training data \"adam\" Vs \"RMSProp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Training data \"adam\" Vs \"RMSProp\"\n",
    "import matplotlib.pyplot as plt\n",
    "fig,plot2 = plt.subplots(1,2,figsize=(10,5))\n",
    "plot2[0].plot(output_train,pred_train,'y.')\n",
    "plot2[0].plot(output_train,output_train,'-')\n",
    "plot2[0].set_xlabel('True output')\n",
    "plot2[0].set_ylabel('Predicted output')\n",
    "plot2[0].set_ylim(-0.05,1.1)\n",
    "plot2[0].set_xlim(-0.05,1.1)\n",
    "plot2[0].set_title(f'Training Data (adam)')\n",
    "plot2[0].text(0,1,f'R2 = {r2_train:.4f}',fontsize=12,color='magenta')\n",
    "plot2[1].plot(output_train,pred_train2,'r*')\n",
    "plot2[1].plot(output_train,output_train,'-')\n",
    "plot2[1].set_ylim(-0.05,1)\n",
    "plot2[1].set_xlim(-0.05,1)\n",
    "plot2[1].set_xlabel('True output')\n",
    "plot2[1].set_ylabel('Predicted output')\n",
    "plot2[1].set_title(f'Training Data (RMSProp)')\n",
    "plot2[1].text(0,0.9,f'R2 = {r2_train2:.4f}',fontsize=12,color='magenta')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Testing data \"adam\" Vs \"RMSProp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Testing data \"adam\" Vs \"RMSProp\"\n",
    "import matplotlib.pyplot as plt\n",
    "fig,plot3 = plt.subplots(1,2,figsize=(10,5))\n",
    "plot3[0].plot(output_test,pred_test,'y.')\n",
    "plot3[0].plot(output_test,output_test,'-')\n",
    "plot3[0].set_xlabel('True output')\n",
    "plot3[0].set_ylabel('Predicted output')\n",
    "plot3[0].set_ylim(-0.05,1.1)\n",
    "plot3[0].set_xlim(-0.05,1.1)\n",
    "plot3[0].set_title(f'Testing Data (adam)')\n",
    "plot3[0].text(0,1,f'R2 = {r2_test:.4f}',fontsize=12,color='magenta')\n",
    "plot3[1].plot(output_test,pred_test2,'r*')\n",
    "plot3[1].plot(output_test,output_test,'-')\n",
    "plot3[1].set_ylim(-0.05,1)\n",
    "plot3[1].set_xlim(-0.05,1)\n",
    "plot3[1].set_xlabel('True output')\n",
    "plot3[1].set_ylabel('Predicted output')\n",
    "plot3[1].set_title(f'Testing Data (RMSProp)')\n",
    "plot3[1].text(0,0.9,f'R2 = {r2_test2:.4f}',fontsize=12,color='magenta')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Beale function\n",
    "def beale_function(x,y):\n",
    "    \"\"\"\n",
    "    Equation of beale function\n",
    "\n",
    "    Inputs:\n",
    "    x and y values\n",
    "\n",
    "    Outputs:\n",
    "    Value of beale function at x and y\n",
    "    \"\"\"\n",
    "    return (1.5-x+x*y)**2 + (2.25-x+x*y**2)**2 + (2.625-x+x*y**3)**2\n",
    "\n",
    "# Generating data for beale function in range and saving to excel\n",
    "def generating_data(step,low=-4.5,high=4.6):\n",
    "    \"\"\"\n",
    "    Generates data points on the beale function for all values of x and y in the range -4.5 < x,y < 4.5\n",
    "\n",
    "    Inputs:\n",
    "    1) step\n",
    "    \n",
    "    Output:\n",
    "    1) DataFrame containing values of (x,y,z)\n",
    "    \"\"\"\n",
    "    X,Y,Z = [],[],[]\n",
    "    for i in np.arange(low,high,step):\n",
    "        for j in np.arange(low,high,step):\n",
    "            X.append(i)\n",
    "            Y.append(j)\n",
    "            Z.append(beale_function(i,j))\n",
    "    # Creating a dataframe for the data generated above\n",
    "    data1 = zip(X,Y,Z)\n",
    "    data2 = pd.DataFrame(data1,columns=['x','y','z'])\n",
    "    return data2\n",
    "\n",
    "# Normarlizing, splitting into inputs and outputs, test splitting \n",
    "def split(data,train_size:float):\n",
    "    \"\"\"\n",
    "    This function takes the data, normalize it and splits into training dataset and testing dataset\n",
    "\n",
    "    Input:\n",
    "    1) data (DataFrame): DataFrame containing labelled data\n",
    "    2) train_size (float): Fraction of train sample to be split\n",
    "\n",
    "    Output:\n",
    "    1) inputs_train: input datasets for training\n",
    "    2) inputs_test: input datasets for testing\n",
    "    2) output_test: output datasets for testing\n",
    "    4) output_test: output datasets for training\n",
    "    \"\"\"\n",
    "    # Normallizing the data\n",
    "    scaler = MinMaxScaler()\n",
    "    data3 = scaler.fit_transform(data.values)\n",
    "    # Splitting the data\n",
    "    inputs = data3[:,0:2]\n",
    "    output = data3[:,-1]\n",
    "    # Splitting the data\n",
    "    inputs_train,inputs_test,output_train,output_test = train_test_split(inputs,output,train_size=train_size,random_state=0)\n",
    "    return inputs_train,inputs_test,output_train,output_test\n",
    "\n",
    "# Structuring ANN with number of hidden layers, nodes and activation functions\n",
    "def network(layers:int,nodes:list,activation_function:str):\n",
    "    \"\"\"\"\n",
    "    Creates a Artificial Neural Network with linear output layer with one node\n",
    "\n",
    "    Inputs:\n",
    "    1) layers (int): Number of layers in the neural network\n",
    "    2) nodes (list): Number of nodes present in each hidden layer starting from first hidden layer\n",
    "    3) activation_function (str): Optimizer for the hidden layers\n",
    "\n",
    "    Output:\n",
    "    1) model: Gives you the nodel as output\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # Add hidden layers\n",
    "    for i in range(layers):\n",
    "        if i == 0:\n",
    "            # For the first hidden layer\n",
    "            model.add(Dense(nodes[i], input_dim=2, activation=activation_function))\n",
    "        else:\n",
    "            model.add(Dense(nodes[i], activation=activation_function))\n",
    "    # Output layer\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    # model.summary()\n",
    "    return model\n",
    "\n",
    "# Training\n",
    "def training(model,optimizer:str,loss_function:str,inputs,output,epoch=100,):\n",
    "    \"\"\"\n",
    "    Trains the data given to the model with given optimizer and loss function with default epochs=100\n",
    "\n",
    "    Inputs:\n",
    "    1) model: A model to be trained\n",
    "    2) optimizer (str): A optimizer for training\n",
    "    3) loss_function (str): Loss function\n",
    "    4) inputs: All inputs of function\n",
    "    5) output: All output of function\n",
    "    6) epoch (int): Number of epochs\n",
    "\n",
    "    Output:\n",
    "    1) model: Gives you trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    model.compile(optimizer =optimizer,loss=loss_function)\n",
    "    history = model.fit(inputs,output,epochs=epoch,validation_split=0.15,verbose=0)\n",
    "    return model\n",
    "\n",
    "# Results\n",
    "def result(predicted,output):\n",
    "    \"\"\"\n",
    "    Takes actual values and predicted values and gives you R2_score and MSE\n",
    "\n",
    "    Inputs:\n",
    "    1) predicted: Output that is predicted by model\n",
    "    2) output: Actual output\n",
    "\n",
    "    Output:\n",
    "    1) r2 (float): R2_score of the given data\n",
    "    2) mse (float): MSE of the given data\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(output,predicted)\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    # Calculating R2 score\n",
    "    r2 = r2_score(output,predicted)\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    return r2,mse\n",
    "\n",
    "# Plotting Training data vs Testing data\n",
    "def plotting(splitted_data,train_prediction,test_prediction,tr,te,variation):\n",
    "    \"\"\"\n",
    "    Plots graphs between Predicted output and Actual output for Training and Testing data\n",
    "\n",
    "    Inputs:\n",
    "    1) splitted_data: Actual data\n",
    "    2) train_prediction: Output predicted by model from training data\n",
    "    3) test_prediction: Output predicted by model from  testing data\n",
    "    4) tr: r2_score of Training data\n",
    "    4) te: r2_score of Testing data\n",
    "    5) variation (str): If plotting for multiple variations\n",
    "    \"\"\"\n",
    "    fig,plot = plt.subplots(1,2,figsize=(10,5))\n",
    "    plot[0].plot(splitted_data[2],train_prediction,'y.')\n",
    "    plot[0].plot(splitted_data[2],splitted_data[2],'-')\n",
    "    plot[0].set_xlabel('True output')\n",
    "    plot[0].set_ylabel('Predicted output')\n",
    "    plot[0].set_ylim(-0.05,1.1)\n",
    "    plot[0].set_xlim(-0.05,1.1)\n",
    "    plot[0].set_title(f'Training Data ({variation})')\n",
    "    plot[0].text(0,1,f'R2 = {tr:.4f}',fontsize=12,color='magenta')\n",
    "    plot[1].plot(splitted_data[3],test_prediction,'r*')\n",
    "    plot[1].plot(splitted_data[3],splitted_data[3],'-')\n",
    "    plot[1].set_ylim(-0.05,1)\n",
    "    plot[1].set_xlim(-0.05,1)\n",
    "    plot[1].set_xlabel('True output')\n",
    "    plot[1].set_ylabel('Predicted output')\n",
    "    plot[1].set_title(f'Testing Data ({variation})')\n",
    "    plot[1].text(0,0.9,f'R2 = {te:.4f}',fontsize=12,color='magenta')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting variation\n",
    "def plotting2(tr_r2,tr_mse,te_r2,te_mse,var=[1,2,3],iter='Combination'):\n",
    "    \"\"\"\n",
    "    Plots two graphs for R2_score and MSE for different variations\n",
    "\n",
    "    Inputs:\n",
    "    1) tr_r2 (list): A list of all r2_score for training data for all variations\n",
    "    2) tr_mse (list): A list of all MSE for training data for all variations\n",
    "    3) te_r2 (list): A list of all r2_score for testing data for all variations\n",
    "    4) te_mse (list): A list of all MSE for testing data for all variations\n",
    "    5) var (list): A list of number of variations for x-axis\n",
    "    6) iter (str): Name of the variable that is being studied\n",
    "    \"\"\"\n",
    "    fig,plot = plt.subplots(1,2,figsize=(10,5))\n",
    "    plot[0].plot(var,tr_r2,'b-',label='Training data')\n",
    "    plot[0].plot(var,te_r2,'g-',label='Testing data')\n",
    "    plot[0].set_xlabel(iter)\n",
    "    plot[0].set_ylabel('R2_score')\n",
    "    # plot[0].grid(True)\n",
    "    plot[0].legend()\n",
    "    plot[1].plot(var,tr_mse,'b-',label='Training data')\n",
    "    plot[1].plot(var,te_mse,'g-',label='Testing data')\n",
    "    plot[1].set_xlabel(iter)\n",
    "    plot[1].set_ylabel('MSE')\n",
    "    # plot[1].grid(True)\n",
    "    plot[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = split(data3,0.7) # Data for variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation of parameters\n",
    "ex_layers = [2,3,4] # Variation in nodes\n",
    "ex_nodes = [18,12,9,6] # Variation in layers\n",
    "ex_activation_functions = ['relu','softmax','tanh'] # Variations in activation functions of all hidden layers\n",
    "ex_epochs = [50,100,150] # Variation in epochs\n",
    "ex_train_size = [0.6,0.8,0.9] # Variation in Training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying number of hidden layers\n",
    "tr_r71,tr_mse71,te_r71,te_mse71 = [],[],[],[]\n",
    "for a in range(0,3,1):\n",
    "    iter71 = f'hidden layers = {ex_layers[a]}'\n",
    "    # Creating a network\n",
    "    ann711 = network(ex_layers[a],ex_nodes,ex_activation_functions[0])\n",
    "    # Training\n",
    "    ann712 = training(ann711,'adam','MSE',splitted_data[0],splitted_data[2],ex_epochs[1])\n",
    "    # Train data\n",
    "    z71_train = ann712.predict(splitted_data[0],verbose=0)\n",
    "    # Test data\n",
    "    z71_test = ann712.predict(splitted_data[1],verbose=0)\n",
    "    # Results\n",
    "    r71,mse71 = result(z71_train,splitted_data[2])\n",
    "    r711,mse711 = result(z71_test,splitted_data[3])\n",
    "    tr_r71.append(r71)\n",
    "    tr_mse71.append(mse71)\n",
    "    te_r71.append(r711)\n",
    "    te_mse71.append(mse711)\n",
    "    #Plotting\n",
    "    plotting(splitted_data,z71_train,z71_test,r71,r711,iter71)\n",
    "plotting2(tr_r71,tr_mse71,te_r71,te_mse71,ex_layers,'Layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying nodes\n",
    "tr_r72,tr_mse72,te_r72,te_mse72 = [],[],[],[]\n",
    "for b in range(0,3,1):\n",
    "    iter72 = f'nodes in hidden layers {ex_nodes[b:b+2]}'\n",
    "    # ex_nodes2.append(ex_nodes[b:b+2])\n",
    "    #Creating a network\n",
    "    ann721 = network(ex_layers[0],ex_nodes[b:b+2],ex_activation_functions[0])\n",
    "    # Training\n",
    "    ann722 = training(ann721,'adam','MSE',splitted_data[0],splitted_data[2],ex_epochs[1])\n",
    "    # Train data results\n",
    "    z72_train = ann722.predict(splitted_data[0],verbose=0)\n",
    "    # Test data results\n",
    "    z72_test = ann722.predict(splitted_data[1],verbose=0)\n",
    "    # Results\n",
    "    r72,mse72 = result(z72_train,splitted_data[2])\n",
    "    r722,mse722 = result(z72_test,splitted_data[3])\n",
    "    tr_r72.append(r72)\n",
    "    tr_mse72.append(mse72)\n",
    "    te_r72.append(r722)\n",
    "    te_mse72.append(mse722)\n",
    "    #Plotting\n",
    "    plotting(splitted_data,z72_train,z72_test,r72,r722,iter72)\n",
    "plotting2(tr_r72,tr_mse71,te_r72,te_mse71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying activation functions\n",
    "tr_r73,tr_mse73,te_r73,te_mse73 = [],[],[],[]\n",
    "for c in range(0,3,1):\n",
    "    iter73 = f'activation function={ex_activation_functions[c]}'\n",
    "    ann731 = network(ex_layers[0],ex_nodes,ex_activation_functions[c])\n",
    "    ann732 = training(ann732,'adam','MSE',splitted_data[0],splitted_data[2],ex_epochs[1])\n",
    "    # Train data\n",
    "    z73_train = ann732.predict(splitted_data[0],verbose=0)\n",
    "    # Test data\n",
    "    z73_test = ann732.predict(splitted_data[1],verbose=0)\n",
    "    # Results\n",
    "    r73,mse73 = result(z73_train,splitted_data[2])\n",
    "    r733,mse733 = result(z73_test,splitted_data[3])\n",
    "    tr_r73.append(r73)\n",
    "    tr_mse73.append(mse73)\n",
    "    te_r73.append(r733)\n",
    "    te_mse73.append(mse733)\n",
    "    #Plotting\n",
    "    plotting(splitted_data,z73_train,z73_test,r73,r733,iter73)\n",
    "plotting2(tr_r73,tr_mse73,te_r73,te_mse73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying epochs\n",
    "tr_r74,tr_mse74,te_r74,te_mse74 = [],[],[],[]\n",
    "for d in range(0,3,1):\n",
    "    iter74 = f'epochs={ex_epochs[d]}'\n",
    "    ann741 = network(ex_layers[0],ex_nodes,ex_activation_functions[0])\n",
    "    ann742 = training(ann741,'adam','MSE',splitted_data[0],splitted_data[2],ex_epochs[d])\n",
    "    # Train data\n",
    "    z74_train = ann742.predict(splitted_data[0],verbose=0)\n",
    "    # Test data\n",
    "    z74_test = ann742.predict(splitted_data[1],verbose=0)\n",
    "    # Results\n",
    "    r74,mse74  = result(z74_train,splitted_data[2])\n",
    "    r744,mse744 = result(z74_test,splitted_data[3])\n",
    "    tr_r74.append(r74)\n",
    "    tr_mse74.append(mse74)\n",
    "    te_r74.append(r744)\n",
    "    te_mse74.append(mse744)\n",
    "    #Plotting\n",
    "    plotting(splitted_data,z74_train,z74_test,r74,r744,iter74)\n",
    "plotting2(tr_r74,tr_mse74,te_r74,te_mse74,ex_epochs,'epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying sample size\n",
    "tr_r75,tr_mse75,te_r75,te_mse75 = [],[],[],[]\n",
    "for e in range(0,3,1):\n",
    "    iter75 = f'train_size= {ex_train_size[e]}'\n",
    "    sp_data = split(data3,ex_train_size[e])\n",
    "    ann751 = network(ex_layers[0],ex_nodes,ex_activation_functions[0])\n",
    "    ann752 = training(ann751,'adam','MSE',sp_data[0],sp_data[2],ex_epochs[1])\n",
    "    # Train data\n",
    "    z75_train = ann752.predict(sp_data[0],verbose=0)\n",
    "    # Test data\n",
    "    z75_test = ann752.predict(sp_data[1],verbose=0)\n",
    "    # Results\n",
    "    r75,mse75 = result(z75_train,sp_data[2])\n",
    "    r755,mse755 = result(z75_test,sp_data[3])\n",
    "    tr_r75.append(r75)\n",
    "    tr_mse75.append(mse75)\n",
    "    te_r75.append(r755)\n",
    "    te_mse75.append(mse755)\n",
    "    #Plotting\n",
    "    plotting(sp_data,z75_train,z75_test,r75,r755,iter75)\n",
    "plotting2(tr_r75,tr_mse75,te_r75,te_mse75,ex_train_size,'Training Data size')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
